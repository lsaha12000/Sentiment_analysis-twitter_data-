{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_df = pd.read_csv('Neutral.csv',names=[\"TEXT\"])\n",
    "negative_df = pd.read_csv('Negative.csv',names=[\"TEXT\"])\n",
    "positive_df = pd.read_csv('Positive.csv',names=[\"TEXT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([negative_df,neutral_df,positive_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final_df.values\n",
    "final = np.reshape(final,(3865,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3865"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i in range(len(negative_df)):\n",
    "    labels.append(0)\n",
    "for i in range(len(neutral_df)):\n",
    "    labels.append(1)\n",
    "for i in range(len(positive_df)):\n",
    "    labels.append(2)\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 5000\n",
    "BATCH_SIZE = 100\n",
    "TAKE_SIZE = 565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_dataset = tf.data.Dataset.from_tensor_slices((final,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'How unhappy  some dogs like it though'   0\n",
      "tf.Tensor(b'How unhappy  some dogs like it though', shape=(), dtype=string) tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for a,b in labeled_dataset.take(1):\n",
    "    print(a.numpy(),\" \",b.numpy())\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.features.text.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7367"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_set = set()\n",
    "for text,_ in labeled_dataset:\n",
    "    tokens = tokenizer.tokenize(text.numpy())\n",
    "    vocab_set.update(tokens)\n",
    "\n",
    "vocab_size = len(vocab_set)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tfds.features.text.TokenTextEncoder(vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_fn(text,label):\n",
    "    encoded_text = encoder.encode(text.numpy())\n",
    "    return encoded_text,label\n",
    "def map_fn(text,label):\n",
    "    return tf.py_function(encode_fn,inp=[text,label],Tout=(tf.int32,tf.int32))\n",
    "\n",
    "encoded_labeled_data = labeled_dataset.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labeled_data=encoded_labeled_data.shuffle(buffer_size=BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7369"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size+=1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = encoded_labeled_data.skip(TAKE_SIZE).padded_batch(BATCH_SIZE,padded_shapes=([-1],[]))\n",
    "test_data = encoded_labeled_data.take(TAKE_SIZE).padded_batch(BATCH_SIZE,padded_shapes=([-1],[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size,20),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n",
    "    tf.keras.layers.Dense(30,activation='relu'),\n",
    "    tf.keras.layers.Dense(3,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 20)          147380    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 40)                6560      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 30)                1230      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 93        \n",
      "=================================================================\n",
      "Total params: 155,263\n",
      "Trainable params: 155,263\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',metrics=['accuracy'],loss='sparse_categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "33/33 [==============================].0976 - accuracy: 0.28 - 5s 2s/step - loss: 1.0989 - accuracy: 0.25 - 5s 2s/step - loss: 1.0991 - accuracy: 0.25 - 5s 1s/step - loss: 1.0985 - accuracy: 0.29 - 5s 1s/step - loss: 1.0987 - accuracy: 0.31 - 5s 844ms/step - loss: 1.0987 - accuracy: 0.318 - 5s 726ms/step - loss: 1.0984 - accuracy: 0.331 - 5s 638ms/step - loss: 1.0982 - accuracy: 0.341 - 5s 569ms/step - loss: 1.0982 - accuracy: 0.341 - 5s 514ms/step - loss: 1.0976 - accuracy: 0.359 - 5s 470ms/step - loss: 1.0972 - accuracy: 0.367 - 5s 432ms/step - loss: 1.0966 - accuracy: 0.379 - 5s 401ms/step - loss: 1.0967 - accuracy: 0.376 - 5s 374ms/step - loss: 1.0965 - accuracy: 0.375 - 5s 350ms/step - loss: 1.0963 - accuracy: 0.377 - 5s 329ms/step - loss: 1.0962 - accuracy: 0.376 - 5s 311ms/step - loss: 1.0959 - accuracy: 0.378 - 5s 295ms/step - loss: 1.0954 - accuracy: 0.381 - 5s 280ms/step - loss: 1.0954 - accuracy: 0.380 - 5s 267ms/step - loss: 1.0954 - accuracy: 0.377 - 5s 256ms/step - loss: 1.0947 - accuracy: 0.382 - 5s 245ms/step - loss: 1.0942 - accuracy: 0.384 - 5s 235ms/step - loss: 1.0943 - accuracy: 0.381 - 5s 226ms/step - loss: 1.0932 - accuracy: 0.388 - 5s 218ms/step - loss: 1.0930 - accuracy: 0.387 - 5s 210ms/step - loss: 1.0927 - accuracy: 0.388 - 5s 203ms/step - loss: 1.0923 - accuracy: 0.388 - 6s 197ms/step - loss: 1.0917 - accuracy: 0.389 - 6s 191ms/step - loss: 1.0913 - accuracy: 0.389 - 6s 185ms/step - loss: 1.0907 - accuracy: 0.390 - 6s 180ms/step - loss: 1.0906 - accuracy: 0.389 - 6s 175ms/step - loss: 1.0903 - accuracy: 0.389 - 6s 170ms/step - loss: 1.0897 - accuracy: 0.390 - 7s 213ms/step - loss: 1.0897 - accuracy: 0.3900 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - ETA: 25s - loss: 1.0700 - accuracy: 0.410 - ETA: 4s - loss: 1.0659 - accuracy: 0.412 - ETA: 2s - loss: 1.0711 - accuracy: 0.39 - ETA: 1s - loss: 1.0604 - accuracy: 0.41 - ETA: 0s - loss: 1.0584 - accuracy: 0.41 - ETA: 0s - loss: 1.0519 - accuracy: 0.42 - ETA: 0s - loss: 1.0506 - accuracy: 0.42 - ETA: 0s - loss: 1.0466 - accuracy: 0.43 - 2s 59ms/step - loss: 1.0431 - accuracy: 0.4436 - val_loss: 0.9888 - val_accuracy: 0.5504\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - ETA: 22s - loss: 1.0161 - accuracy: 0.530 - ETA: 4s - loss: 0.9638 - accuracy: 0.548 - ETA: 2s - loss: 0.9382 - accuracy: 0.55 - ETA: 1s - loss: 0.9175 - accuracy: 0.57 - ETA: 0s - loss: 0.8966 - accuracy: 0.58 - ETA: 0s - loss: 0.8709 - accuracy: 0.61 - ETA: 0s - loss: 0.8468 - accuracy: 0.63 - ETA: 0s - loss: 0.8195 - accuracy: 0.65 - 2s 58ms/step - loss: 0.7984 - accuracy: 0.6764 - val_loss: 0.5200 - val_accuracy: 0.8673\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - ETA: 23s - loss: 0.5010 - accuracy: 0.910 - ETA: 4s - loss: 0.5001 - accuracy: 0.894 - ETA: 2s - loss: 0.4768 - accuracy: 0.90 - ETA: 1s - loss: 0.4544 - accuracy: 0.91 - ETA: 0s - loss: 0.4488 - accuracy: 0.90 - ETA: 0s - loss: 0.4374 - accuracy: 0.90 - ETA: 0s - loss: 0.4211 - accuracy: 0.90 - ETA: 0s - loss: 0.4179 - accuracy: 0.90 - 2s 57ms/step - loss: 0.4130 - accuracy: 0.9027 - val_loss: 0.2506 - val_accuracy: 0.9469\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - ETA: 24s - loss: 0.2215 - accuracy: 0.930 - ETA: 4s - loss: 0.2875 - accuracy: 0.910 - ETA: 2s - loss: 0.2523 - accuracy: 0.93 - ETA: 1s - loss: 0.2595 - accuracy: 0.92 - ETA: 1s - loss: 0.2476 - accuracy: 0.93 - ETA: 0s - loss: 0.2516 - accuracy: 0.93 - ETA: 0s - loss: 0.2420 - accuracy: 0.93 - ETA: 0s - loss: 0.2335 - accuracy: 0.93 - ETA: 0s - loss: 0.2281 - accuracy: 0.93 - ETA: 0s - loss: 0.2239 - accuracy: 0.93 - 2s 61ms/step - loss: 0.2238 - accuracy: 0.9400 - val_loss: 0.1489 - val_accuracy: 0.9646\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,epochs=5,validation_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
